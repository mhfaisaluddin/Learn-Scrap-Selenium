{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Selenium Scrape on LinkedIn Job Post\n",
    "References: Web Scraping LinkedIn Job Page with Selenium Python _ by Mert Kucukkuru _ Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "It is a notebook file that stores dirty code for the project.\n",
    "- Start the project by installing the required library (selenium), and setting up the web driver (chrome web driver).\n",
    "- Create a .txt file that store your username & LinkedIn password.\n",
    "- The code will scrape the job offers and their info by visiting each offer scraped on every page.\n",
    "- Store the job offer in a .csv file and the description in a .txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The whole trial code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7576\\2280551933.py:17: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "## PART I\n",
    "# setup the path for the webdriver\n",
    "path = 'C:/Users/User/Downloads/chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "# maximizing the window\n",
    "driver.maximize_window()\n",
    "driver.switch_to.window(driver.current_window_handle)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# entering the site \n",
    "driver.get('https://www.linkedin.com/login')\n",
    "time.sleep(2) # made the program wait 2 sec to be sure that the page is loaded\n",
    "\n",
    "# user credentials\n",
    "# reading txt file store your account id and password\n",
    "with open('user_credentials.txt', 'r',encoding='utf-8') as file:\n",
    "    user_credentials = file.readlines()\n",
    "    user_credentials = [line.rstrip() for line in user_credentials]\n",
    "\n",
    "user_name = user_credentials[0] # your account id\n",
    "password = user_credentials[1] # your account password\n",
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"username\"]').send_keys(user_name)\n",
    "driver.find_element(By.XPATH,'//*[@id=\"password\"]').send_keys(password)\n",
    "time.sleep(2)\n",
    "\n",
    "# login button\n",
    "driver.find_element(By.XPATH,'//*[@id=\"organic-div\"]/form/div[3]/button').click()\n",
    "driver.implicitly_wait(20)\n",
    "\n",
    "# job page\n",
    "driver.find_element(By.XPATH,'//*[@id=\"global-nav\"]/div/nav/ul/li[3]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# go to search result\n",
    "search_keyword = 'data science'\n",
    "search_loc = 'indonesia'\n",
    "driver.find_element(By.XPATH,'//*[@id=\"global-nav-search\"]/div/div[2]/div[2]').click()\n",
    "driver.find_element(By.XPATH, '//*[@id=\"jobs-search-box-keyword-id-ember249\"]').send_keys(search_keyword)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"jobs-search-box-location-id-ember249\"]').send_keys(search_loc + '\\n')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "## PART II \n",
    "# get all links for the offers\n",
    "links = []\n",
    "\n",
    "print('Links are being collected now.')\n",
    "try:\n",
    "    # navigate 3 pages\n",
    "    for page in range (2,4): \n",
    "        time.sleep(2)\n",
    "        jobs_block = driver.find_element(By.CLASS_NAME, 'scaffold-layout__list-container')\n",
    "        jobs_list = jobs_block.find_elements(By.CSS_SELECTOR, '.jobs-search-results__list-item')\n",
    "\n",
    "        for job in jobs_list:\n",
    "            all_links = job.find_elements(By.TAG_NAME, 'a')\n",
    "            for a in all_links:\n",
    "                if str(a.get_attribute('href')).startswith('https://www.linkedin.com/jobs/view') and a.get_attribute('href') not in links:\n",
    "                    links.append(a.get_attribute('href'))\n",
    "                else:\n",
    "                    pass\n",
    "            # scroll down\n",
    "            driver.execute_script('arguments[0].scrollIntoView();', job)\n",
    "\n",
    "        print(f'Collecting the links in the page : {page-1}')\n",
    "        # go to next page through loop\n",
    "        driver.find_element(By.XPATH, f\"//button[@aria-label='Page {page}']\").click()\n",
    "        time.sleep(3)\n",
    "except:\n",
    "    pass\n",
    "print('Found' + str(len(links)) + 'links for job offers')\n",
    "\n",
    "# try and except: pass block in case there is a missing element in a page\n",
    "# it prevents automation from failing and stopping the whole process instead of passing the problematic 1 specific page \n",
    "\n",
    "\n",
    "## PART III\n",
    "# create empty list to store the info\n",
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "work_methods = []\n",
    "post_dates = []\n",
    "work_times = []\n",
    "job_desc = []\n",
    "\n",
    "i = 0 ; j = 1\n",
    "\n",
    "# visit each link one by one to scrape the info\n",
    "print('Visiting the links and collecting info just started.')\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        driver.get(links[i])\n",
    "        i=i+1\n",
    "        time.sleep(3)\n",
    "        # click 'see more'\n",
    "        driver.find_element(By.CLASS_NAME, 'artdeco-card__actions').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # find the general information from the job offers\n",
    "    contents = driver.find_elements(By.CLASS_NAME, 'p5')\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element(By.TAG_NAME,'h1').text)\n",
    "            company_names.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').text)\n",
    "            company_locations.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__bullet').text)\n",
    "            work_methods.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__workplace-type').text)\n",
    "            post_dates.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__posted-date').text)\n",
    "            work_times.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__job-insight').text)\n",
    "            print(f'Scraping the Job Offer {j} DONE.')\n",
    "            j+=1\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "\n",
    "    # scraping the job description\n",
    "    job_description = driver.find_elements(By.CLASS_NAME,'jobs-description__content')\n",
    "    for description in job_description:\n",
    "        job_text = description.find_element(By.CLASS_NAME,'jobs-box__html-content').text\n",
    "        job_desc.append(job_text)\n",
    "        print(f'Scraping the Job Offer {j}')\n",
    "        time.sleep(4)\n",
    "\n",
    "\n",
    "# PART IV\n",
    "# creating the dataframe\n",
    "df = (pd.DataFrame(list(zip(job_titles,company_names,company_locations,\n",
    "                            work_methods,post_dates,work_times)),\n",
    "                            columns=['job_title','company_name','company_location',\n",
    "                                    'work_method','post_date','work_time']))\n",
    "\n",
    "# storing into csv file\n",
    "df.to_csv('job_offers.csv', index=False)\n",
    "\n",
    "# pull out the job description as txt file\n",
    "with open('job_descriptions.txt', 'w',encoding='utf-8') as f:\n",
    "    for line in job_desc:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the data\n",
    "datas = pd.read_csv('job_offers.csv')\n",
    "datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dirty notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8488\\2853580805.py:16: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links are being collected now.\n",
      "Collecting the links in the page : 1\n",
      "Found25links for job offers\n",
      "Visiting the links and collecting info just started.\n",
      "Scraping the Job Offer 1 DONE.\n",
      "Scraping the Job Offer 2\n",
      "Scraping the Job Offer 2 DONE.\n",
      "Scraping the Job Offer 3\n",
      "Scraping the Job Offer 3 DONE.\n",
      "Scraping the Job Offer 4\n",
      "Scraping the Job Offer 4 DONE.\n",
      "Scraping the Job Offer 5\n",
      "Scraping the Job Offer 5 DONE.\n",
      "Scraping the Job Offer 6\n",
      "Scraping the Job Offer 6 DONE.\n",
      "Scraping the Job Offer 7\n",
      "Scraping the Job Offer 7 DONE.\n",
      "Scraping the Job Offer 8\n",
      "Scraping the Job Offer 8\n",
      "Scraping the Job Offer 8 DONE.\n",
      "Scraping the Job Offer 9\n",
      "Scraping the Job Offer 9 DONE.\n",
      "Scraping the Job Offer 10\n",
      "Scraping the Job Offer 10 DONE.\n",
      "Scraping the Job Offer 11\n",
      "Scraping the Job Offer 11 DONE.\n",
      "Scraping the Job Offer 12\n",
      "Scraping the Job Offer 12 DONE.\n",
      "Scraping the Job Offer 13\n",
      "Scraping the Job Offer 13 DONE.\n",
      "Scraping the Job Offer 14\n",
      "Scraping the Job Offer 14 DONE.\n",
      "Scraping the Job Offer 15\n",
      "Scraping the Job Offer 15 DONE.\n",
      "Scraping the Job Offer 16\n",
      "Scraping the Job Offer 16 DONE.\n",
      "Scraping the Job Offer 17\n",
      "Scraping the Job Offer 17 DONE.\n",
      "Scraping the Job Offer 18\n",
      "Scraping the Job Offer 18\n",
      "Scraping the Job Offer 18 DONE.\n",
      "Scraping the Job Offer 19\n",
      "Scraping the Job Offer 19 DONE.\n",
      "Scraping the Job Offer 20\n",
      "Scraping the Job Offer 20\n",
      "Scraping the Job Offer 20 DONE.\n",
      "Scraping the Job Offer 21\n",
      "Scraping the Job Offer 21 DONE.\n",
      "Scraping the Job Offer 22\n",
      "Scraping the Job Offer 22 DONE.\n",
      "Scraping the Job Offer 23\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "## PART I\n",
    "# setup the path for the webdriver\n",
    "# driver path\n",
    "\n",
    "path = 'C:/Users/User/Downloads/chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "# maximizing the window\n",
    "driver.maximize_window()\n",
    "driver.switch_to.window(driver.current_window_handle)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# entering the site \n",
    "driver.get('https://www.linkedin.com/login')\n",
    "time.sleep(2) # it will make the program wait 2 sec to be sure that the page is loaded\n",
    "\n",
    "# user credentials\n",
    "# reading txt file, storing your account id pass\n",
    "\n",
    "with open('user_credentials.txt', 'r',encoding='utf-8') as file:\n",
    "    user_credentials = file.readlines()\n",
    "    user_credentials = [line.rstrip() for line in user_credentials]\n",
    "\n",
    "user_name = user_credentials[0] # 1st \n",
    "password = user_credentials[1] # 2nd\n",
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"username\"]').send_keys(user_name)\n",
    "driver.find_element(By.XPATH,'//*[@id=\"password\"]').send_keys(password)\n",
    "time.sleep(2)\n",
    "\n",
    "# login button\n",
    "driver.find_element(By.XPATH,'//*[@id=\"organic-div\"]/form/div[3]/button').click()\n",
    "driver.implicitly_wait(20)\n",
    "\n",
    "# job page\n",
    "driver.find_element(By.XPATH,'//*[@id=\"global-nav\"]/div/nav/ul/li[3]/a').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# goto search result directly via link\n",
    "driver.get('https://www.linkedin.com/jobs/search/?currentJobId=3326797135&geoId=102478259&keywords=data%20science&location=Indonesia&refresh=true')\n",
    "time.sleep(1)\n",
    "#driver.find_element('xpath','//*[@id=\"jobs-search-box-keyword-id-ember250\"]').click()\n",
    "#search_keyword = 'data science'\n",
    "#search_loc = 'indonesia'\n",
    "#driver.find_element('xpath', '//*[@id=\"jobs-search-box-keyword-id-ember250\"]').send_keys(search_keyword)\n",
    "#driver.find_element('xpath', '//*[@id=\"jobs-search-box-keyword-id-ember250\"]').send_keys(search_loc).sendKeys(Keys.ENTER)\n",
    "\n",
    "\n",
    "## PART II \n",
    "# get all links for these offers\n",
    "links = []\n",
    "# navigate 2 pages\n",
    "print('Links are being collected now.')\n",
    "try:\n",
    "    for page in range (2,3):\n",
    "        time.sleep(2)\n",
    "        jobs_block = driver.find_element(By.CLASS_NAME, 'scaffold-layout__list-container')\n",
    "        jobs_list = jobs_block.find_elements(By.CSS_SELECTOR, '.jobs-search-results__list-item')\n",
    "\n",
    "        for job in jobs_list:\n",
    "            all_links = job.find_elements(By.TAG_NAME, 'a')\n",
    "            for a in all_links:\n",
    "                if str(a.get_attribute('href')).startswith('https://www.linkedin.com/jobs/view') and a.get_attribute('href') not in links:\n",
    "                    links.append(a.get_attribute('href'))\n",
    "                else:\n",
    "                    pass\n",
    "            # scroll down\n",
    "            driver.execute_script('arguments[0].scrollIntoView();', job)\n",
    "\n",
    "        print(f'Collecting the links in the page : {page-1}')\n",
    "        # go to next page\n",
    "        driver.find_element(By.XPATH, f\"//button[@aria-label='Page {page}']\").click()\n",
    "        time.sleep(3)\n",
    "except:\n",
    "    pass\n",
    "print('Found' + str(len(links)) + 'links for job offers')\n",
    "\n",
    "\n",
    "## PART III\n",
    "# create empty list to store the info\n",
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "work_methods = []\n",
    "post_dates = []\n",
    "work_times = []\n",
    "job_desc = []\n",
    "\n",
    "i = 0 ; j = 1\n",
    "\n",
    "# visit each link one by one to scrape the info\n",
    "print('Visiting the links and collecting info just started.')\n",
    "for i in range(len(links)):\n",
    "    try:\n",
    "        driver.get(links[i])\n",
    "        i=i+1\n",
    "        time.sleep(3)\n",
    "        # click 'see more'\n",
    "        driver.find_element(By.CLASS_NAME, 'artdeco-card__actions').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # find the general information of the job offers\n",
    "    contents = driver.find_elements(By.CLASS_NAME, 'p5')\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element(By.TAG_NAME,'h1').text)\n",
    "            company_names.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__company-name').text)\n",
    "            company_locations.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__bullet').text)\n",
    "            work_methods.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__workplace-type').text)\n",
    "            post_dates.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__posted-date').text)\n",
    "            work_times.append(content.find_element(By.CLASS_NAME,'jobs-unified-top-card__job-insight').text)\n",
    "            print(f'Scraping the Job Offer {j} DONE.')\n",
    "            j+=1\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(2)\n",
    "\n",
    "    # scraping the job description\n",
    "    job_description = driver.find_elements(By.CLASS_NAME,'jobs-description__content')\n",
    "    for description in job_description:\n",
    "        job_text = description.find_element(By.CLASS_NAME,'jobs-box__html-content').text\n",
    "        job_desc.append(job_text)\n",
    "        print(f'Scraping the Job Offer {j}')\n",
    "        time.sleep(4)\n",
    "\n",
    "# PART IV\n",
    "# creating the dataframe\n",
    "df = (pd.DataFrame(list(zip(job_titles,company_names,company_locations,\n",
    "                            work_methods,post_dates,work_times)),\n",
    "                            columns=['job_title','company_name','company_location',\n",
    "                                    'work_method','post_date','work_time']))\n",
    "\n",
    "# storing into csv file\n",
    "df.to_csv('job_offers.csv', index=False)\n",
    "\n",
    "# pull out the job description as txt file\n",
    "with open('job_descriptions.txt', 'w',encoding='utf-8') as f:\n",
    "    for line in job_desc:\n",
    "        f.write(line)\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_location</th>\n",
       "      <th>work_method</th>\n",
       "      <th>post_date</th>\n",
       "      <th>work_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Sribuu (YC W22)</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Remote</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jr Data Scientist</td>\n",
       "      <td>PT Imani Prima</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>4 weeks ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI Research Scientist</td>\n",
       "      <td>PT Bank Rakyat Indonesia (Persero) Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer Intern</td>\n",
       "      <td>dentsu international</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Full-time · Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Citi</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Client Engineering - Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst Lead</td>\n",
       "      <td>PT Alto Network</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Binar Academy</td>\n",
       "      <td>Tangerang, Banten, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Client Engineering - Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>IDR7,000,000/month - IDR15,000,000/month · Ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Silvertech Asia</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist - Commercial Ecosystem</td>\n",
       "      <td>Philip Morris International</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Management Information &amp; Business Intelligence...</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Visualization</td>\n",
       "      <td>PT. XL Axiata Tbk</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>3 weeks ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>dentsu international</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Client Engineering - Data Engineer</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Internship - Information Technology</td>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Automation Data Analyst</td>\n",
       "      <td>DANA Indonesia</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Internship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Sunartha</td>\n",
       "      <td>Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Analyst (Statistics/Python/BI) (Bangkok-b...</td>\n",
       "      <td>Agoda</td>\n",
       "      <td>Bali, Indonesia</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Consultant/Senior Consultant - Artificial Inte...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Sayurbox</td>\n",
       "      <td>Jakarta Metropolitan Area</td>\n",
       "      <td>On-site</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Full-time · Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Business Intelligence Associate</td>\n",
       "      <td>DANA Indonesia</td>\n",
       "      <td>Jakarta, Jakarta, Indonesia</td>\n",
       "      <td>On-site</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title  \\\n",
       "0                               Data Scientist Intern   \n",
       "1                                   Jr Data Scientist   \n",
       "2                               AI Research Scientist   \n",
       "3                                Data Engineer Intern   \n",
       "4                                  Business Analytics   \n",
       "5                 Client Engineering - Data Scientist   \n",
       "6                                   Data Analyst Lead   \n",
       "7                                       Data Engineer   \n",
       "8                 Client Engineering - Data Scientist   \n",
       "9                                       Data Engineer   \n",
       "10              Data Scientist - Commercial Ecosystem   \n",
       "11  Management Information & Business Intelligence...   \n",
       "12                                 Data Visualization   \n",
       "13                                     Data Scientist   \n",
       "14                 Client Engineering - Data Engineer   \n",
       "15                Internship - Information Technology   \n",
       "16                            Automation Data Analyst   \n",
       "17                                Data Analyst Intern   \n",
       "18  Data Analyst (Statistics/Python/BI) (Bangkok-b...   \n",
       "19  Consultant/Senior Consultant - Artificial Inte...   \n",
       "20                                     Data Scientist   \n",
       "21                    Business Intelligence Associate   \n",
       "\n",
       "                              company_name              company_location  \\\n",
       "0                          Sribuu (YC W22)            Jakarta, Indonesia   \n",
       "1                           PT Imani Prima   Jakarta, Jakarta, Indonesia   \n",
       "2   PT Bank Rakyat Indonesia (Persero) Tbk            Jakarta, Indonesia   \n",
       "3                     dentsu international   Jakarta, Jakarta, Indonesia   \n",
       "4                                     Citi   Jakarta, Jakarta, Indonesia   \n",
       "5                                      IBM   Jakarta, Jakarta, Indonesia   \n",
       "6                          PT Alto Network   Jakarta, Jakarta, Indonesia   \n",
       "7                            Binar Academy  Tangerang, Banten, Indonesia   \n",
       "8                                      IBM   Jakarta, Jakarta, Indonesia   \n",
       "9                          Silvertech Asia   Jakarta, Jakarta, Indonesia   \n",
       "10             Philip Morris International   Jakarta, Jakarta, Indonesia   \n",
       "11                                 Cargill   Jakarta, Jakarta, Indonesia   \n",
       "12                       PT. XL Axiata Tbk            Jakarta, Indonesia   \n",
       "13                    dentsu international   Jakarta, Jakarta, Indonesia   \n",
       "14                                     IBM   Jakarta, Jakarta, Indonesia   \n",
       "15                        Procter & Gamble   Jakarta, Jakarta, Indonesia   \n",
       "16                          DANA Indonesia            Jakarta, Indonesia   \n",
       "17                                Sunartha            Jakarta, Indonesia   \n",
       "18                                   Agoda               Bali, Indonesia   \n",
       "19                                Deloitte   Jakarta, Jakarta, Indonesia   \n",
       "20                                Sayurbox     Jakarta Metropolitan Area   \n",
       "21                          DANA Indonesia   Jakarta, Jakarta, Indonesia   \n",
       "\n",
       "   work_method     post_date  \\\n",
       "0       Remote    4 days ago   \n",
       "1      On-site   4 weeks ago   \n",
       "2      On-site    2 days ago   \n",
       "3      On-site   3 weeks ago   \n",
       "4      On-site     1 day ago   \n",
       "5      On-site    1 week ago   \n",
       "6      On-site     1 day ago   \n",
       "7      On-site    1 week ago   \n",
       "8      On-site  20 hours ago   \n",
       "9      On-site    2 days ago   \n",
       "10     On-site   5 hours ago   \n",
       "11     On-site  13 hours ago   \n",
       "12     On-site   3 weeks ago   \n",
       "13     On-site    1 week ago   \n",
       "14      Hybrid   2 weeks ago   \n",
       "15      Hybrid    1 week ago   \n",
       "16      Hybrid    3 days ago   \n",
       "17     On-site    2 days ago   \n",
       "18      Remote    1 week ago   \n",
       "19     On-site  13 hours ago   \n",
       "20     On-site    2 days ago   \n",
       "21     On-site   5 hours ago   \n",
       "\n",
       "                                            work_time  \n",
       "0                                          Internship  \n",
       "1                               Full-time · Associate  \n",
       "2                        Full-time · Mid-Senior level  \n",
       "3                              Full-time · Internship  \n",
       "4                                           Full-time  \n",
       "5                                           Full-time  \n",
       "6                        Full-time · Mid-Senior level  \n",
       "7                                           Full-time  \n",
       "8   IDR7,000,000/month - IDR15,000,000/month · Ful...  \n",
       "9                                           Full-time  \n",
       "10                       Full-time · Mid-Senior level  \n",
       "11                            Full-time · Entry level  \n",
       "12                            Full-time · Entry level  \n",
       "13                                          Full-time  \n",
       "14                                          Full-time  \n",
       "15                              Full-time · Associate  \n",
       "16                                         Internship  \n",
       "17                       Full-time · Mid-Senior level  \n",
       "18                            Full-time · Entry level  \n",
       "19                            Full-time · Entry level  \n",
       "20                            Full-time · Entry level  \n",
       "21                              Full-time · Associate  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = pd.read_csv('job_offers.csv')\n",
    "datas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
